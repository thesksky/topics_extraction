{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tokenizer, stemmer and stop words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stemmer = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inFilePath = \"C:\\\\Users\\\\thesk\\\\Desktop\\\\RAW_recipes_name.xlsx\"\n",
    "\n",
    "df = pd.read_excel(open(inFilePath,'rb'))\n",
    "strdata = df.values.tolist() #each row becomes a separate list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['arriba   baked winter squash mexican style'],\n",
       " ['a bit different  breakfast pizza'],\n",
       " ['all in the kitchen  chili'],\n",
       " ['alouette  potatoes'],\n",
       " ['amish  tomato ketchup  for canning'],\n",
       " ['apple a day  milk shake'],\n",
       " ['aww  marinated olives'],\n",
       " ['backyard style  barbecued ribs'],\n",
       " ['bananas 4 ice cream  pie'],\n",
       " ['beat this  banana bread']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strdata[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenizer.tokenize(str(i)) for i in strdata] #tokenize words in lists\n",
    "\n",
    "cleaned_list = []\n",
    "\n",
    "for token in tokens:\n",
    "    stopped = [i for i in token if str(i).lower() not in stop_words] #remove stop words\n",
    "    longer = [i for i in stopped if len(i) > 2]\n",
    "    stemmed = [stemmer.stem(i) for i in longer] #stem words\n",
    "    lemmed = [wnl.lemmatize(i) for i in stemmed]\n",
    "    cleaned_list.append(lemmed) #append stemmed words to list\n",
    "\n",
    "backtodf = pd.DataFrame(cleaned_list) #convert list back to pandas dataframe\n",
    "remove_NaN = backtodf.replace(np.nan, '', regex=True) #remove None (which return as words (str))\n",
    "mergeddf = remove_NaN.astype(str).apply(lambda x: ' '.join(x), axis=1) #convert cells to strings, merge columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    arriba bake winter squash mexican style     \n",
       "1               bit differ breakfast pizza       \n",
       "2                          kitchen chili         \n",
       "3                         alouett potato         \n",
       "4             amish tomato ketchup canning       \n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergeddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Create a Dictionary from the data \n",
    "dictionary = corpora.Dictionary(cleaned_list)\n",
    "\n",
    "# Convert to Bag-of-words corpus and save both for future use\n",
    "corpus = [dictionary.doc2bow(text) for text in cleaned_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))\n",
    "dictionary.save('dictionary.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.054*\"chocol\" + 0.054*\"cake\" + 0.040*\"cooki\" + 0.029*\"strawberri\" + 0.022*\"appl\"')\n",
      "(1, '0.075*\"salad\" + 0.032*\"sauc\" + 0.030*\"chicken\" + 0.028*\"yummi\" + 0.022*\"dip\"')\n",
      "(2, '0.044*\"chees\" + 0.039*\"chicken\" + 0.037*\"zucchini\" + 0.028*\"tomato\" + 0.027*\"bake\"')\n",
      "(3, '0.053*\"sweet\" + 0.042*\"bean\" + 0.036*\"pie\" + 0.035*\"potato\" + 0.029*\"white\"')\n",
      "(4, '0.056*\"soup\" + 0.029*\"bread\" + 0.029*\"veget\" + 0.024*\"whole\" + 0.023*\"pork\"')\n"
     ]
    }
   ],
   "source": [
    "# Now asking LDA to find N topics in the data:\n",
    "\n",
    "NUM_TOPICS = 5\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=5)\n",
    "ldamodel.save('model5.gensim')\n",
    "\n",
    "topics = ldamodel.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, above we should see the some of the following recipe types: <br>\n",
    "Breads, Dessert, Dips/salad, Sandwiches, Side dishes, Soups/stews, Breakfast, Main courses <br>\n",
    "(like on this added picture)\n",
    "<img src=\"food_classification.png\" width=\"300\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
